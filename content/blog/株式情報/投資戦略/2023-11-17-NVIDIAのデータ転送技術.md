---
title: NVDAのモート：データ転送技術がAIの効率性を押し上げる
description: NVIDIAのAI分野での競争優位性を詳細分析。H100 GPUの演算能力だけでなく、NVLink&NVSwitch+Infinibandで実現する革新的データ転送技術がAIトレーニング効率を圧倒的に向上させ競合他社を引き離す理由を解説。
slug: nvda-moat-data-transfer-ai-efficiency
publishedAt: 2023-11-17T05:15:00
coverImage: /Hero/nvda-moat-data-transfer-ai-efficiency
category: Stocks
tags: ['投資戦略', 'NVDA']
---

NVIDIA (NVDA)は、生成AIが革新を遂げる中でその基盤を支える際立った企業として投資家たちの注目を集めています。生成AIは膨大なデータを学習させるために高度な計算力を必要とします。この計算力を提供するGPUを競合他社も提供していますが、NVDAへの熱狂具合は他社には及びません。

(記事時点の各社YTDはNVDAが193%、AMDが54%、INTCが35%)

NVDAがなぜ他社を凌駕する注目を集めるのか、その理由はNVDAが業界で独自の地位を築いているためです。生成AIに関する発表を見ると、演算能力があることは大前提としてさらに強力なデータ転送能力がAIのトレーニングには必要不可欠であることが分かります。AMDなどの競合他社のGPUも演算能力は向上していますがNVDAは圧倒的なデータ転送技術を有しており、生成AIのトレーニングにおいて他社を圧倒すると見られています。

ではNVDAの持っている高度なデータ転送技術とは何かを見てみましょう。

# AIの効率性とNVDAのデータ転送技術

AIの効率性は、演算能力とデータ転送能力の両面を含むものです。機械学習(ML)の効率性は、MLPerfという業界標準のベンチマークによって測定されています。NVDAのH100を利用したクラスター環境は、このベンチマークの8つの測定項目全てで記録を保持し、業界をリードする存在であることが示されています(参照: [NVIDIA H100 GPUs Set Standard for Generative AI in Debut MLPerf Benchmark ](https://blogs.nvidia.com/blog/generative-ai-debut-mlperf/))。

この事実は、NVDAが大規模な言語モデル(LLM)、医療画像、音声認識、画像処理など多岐にわたる分野で活用可能なGPUを保有していることを示しています。

AIのトレーニングは通常、多数のGPUをサーバー内およびサーバー間で連携させ、大規模に実行されます。NVDAが注目されるのは、サーバー間でのデータ転送における[NVLink](https://blogs.nvidia.com/blog/what-is-nvidia-nvlink/) & [NVSwitch](https://www.nvidia.com/ja-jp/data-center/nvlink/) + [Infiniband](https://www.nvidia.com/ja-jp/networking/products/infiniband/)といったデータ転送技術の強みに由来します。

データ転送能力をさらに分類すると、サーバー内の複数のGPUへのデータ転送と、高度に接続されたサーバー間でのデータ転送の2つに分けられます。NVLinkとNVSwitchは前者に関連し、Infinibandは後者に関与します。

## NVLinkとNVSwitchによるマルチGPU通信

兆単位のパラメータを高速に処理するには、GPU間を高速通信で接続し、マルチノードかつマルチGPUシステムを構築する必要があります。NVLinkは、現在の第4世代ではPCIe Gen5の帯域の7倍以上の接続を実現し、GPUとGPUを直接相互接続する技術です。一方、NVSwitchはこれらのNVLinkを統合し、高速通信を実現しつつネットワーク内でのデータ転送量を制御する技術です。

## Infinibandによる高速ネットワーク

高速ネットワークでは、AI開発のためデータセンターに流れ込む大量のデータ転送をCPUによるオーバーヘッドを極力排除し、Infinibandを用いたクラウド環境のベンチマークは、ローカルデータセンターでの測定と同等のパフォーマンスを記録しており、Infinibandが低遅延ネットワーキングとして非常に優れた性能を持っていることを示唆しています。

## NVLink & NVSwitch + Infinibandの利点

これらの技術が組み合わさることで、データセンターは高度なエネルギー効率を実現できます。同等のパフォーマンスを維持しつつ必要なサーバーの数を減らし、場所と電力を節約できます。これにより、節約されたリソースを新たなサーバーの導入に充てることで、パフォーマンスをさらに向上させることが可能となります。

そして、これらのサーバーノードをInfinibandの低遅延ネットワークで接続することで、サーバーノード増加による負担を軽減できます。

# 演算能力とデータ転送能力の掛け合わせによる高速化

先述の業界標準ベンチマークは約6か月前の情報ですが、[最新のNVDAの報告](https://blogs.nvidia.com/blog/scaling-ai-training-mlperf/)によれば、ネットワーク能力の向上によりベンチマーク結果は約3倍も高速化しました。これは、同じH100を使用したベンチマークでありながら、大幅な性能向上を達成したことを意味し、AIの効率性が演算能力とデータ転送能力の相乗効果であることを示しています。

今後、多くの企業がそれぞれの保有するデータを機械学習し、独自のLLMを作成する動きが拡大することが予想されます。こうした取り組みにおいて、NVDAのハードウェアを利用することでトレーニング時間の短縮、コスト削減、エネルギーの節約、市場投入までの時間短縮が可能となり、大きなアドバンテージを生み出します。LLM自体が現在も進化を続けていることから、長期的にLLMトレーニングは継続されるものと見られます。

演算能力だけでなく、強力なデータ転送能力を兼ね備えたNVDAに対する注目は、非常に説得力があります。この優位性はしばらく崩れることはないのではないでしょうか？
